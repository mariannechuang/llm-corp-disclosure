{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name_before_greenwashing = \"malicious_greenwashing_output/testing_greenwashing_prompt_v1/stratified_set/original_ratings_non-a_list_2022_stratified_set_of_80.csv\"\n",
    "file_name_before_greenwashing = \"malicious_greenwashing_output/before_greenwashing_indicative_ratings_80.csv\"\n",
    "file_name_after_greenwashing = 'malicious_greenwashing_output/testing_greenwashing_prompt_v0/indicative/indicative_80_new_average_ratings.csv'\n",
    "#file_name_after_greenwashing = \"malicious_greenwashing_output/rerating_companies_malicious/average_new_ratings_2022_stratified_set.csv\"\n",
    "\n",
    "# df_average_companies = df#pd.read_csv(file_name_before_greenwashing)\n",
    "df_average_companies = pd.read_csv(file_name_before_greenwashing)\n",
    "df_average_a_list_companies = pd.read_csv(file_name_after_greenwashing)\n",
    "\n",
    "print(df_average_companies.columns)\n",
    "print(df_average_a_list_companies.columns)\n",
    "df_average_companies[\"Average\"].hist(bins=[1,1.5,2,2.5,3,3.5,4,4.5,5], alpha = 0.5, label='Before Greenwashing', color='blue')\n",
    "\n",
    "# plt.hist(df_average_companies[\"Average\"], bins=[1,1.5,2,2.5,3,3.5,4,4.5,5], alpha = 0.5, label='Non A-list Companies', color='blue')\n",
    "plt.hist(df_average_a_list_companies[\"Average\"], bins=[1,1.5,2,2.5,3,3.5,4,4.5,5], alpha = 0.5, label='After Greenwashing', color='red')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "hist_title = \"Company Ratings Before and After Greenwashing (2022 50 Companies)\"\n",
    "plt.title(hist_title)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# png_name = prefix + \"rating_result_graphs\" + \"/\" + year + \"/Combined_average_ratings_\" + year + \".png\"\n",
    "# plt.savefig(png_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following graphs one new set against the original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_before_greenwashing = \"malicious_greenwashing_output/before_greenwashing_indicative_ratings_80.csv\"\n",
    "file_name_after_greenwashing = 'malicious_greenwashing_output/testing_greenwashing_prompt_v3/indicative/80_new_average_ratings.csv'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Assuming both CSVs are already read into these variables\n",
    "df_average_companies = pd.read_csv(file_name_before_greenwashing)\n",
    "df_average_a_list_companies = pd.read_csv(file_name_after_greenwashing)\n",
    "\n",
    "# Check the columns in both DataFrames\n",
    "print(df_average_companies.columns)\n",
    "print(df_average_a_list_companies.columns)\n",
    "\n",
    "# Merge the two datasets based on 'Company'\n",
    "merged_df = pd.merge(df_average_companies[['Company', 'Average']], df_average_a_list_companies[['Company', 'Average']], on='Company', suffixes=('_Before', '_After'))\n",
    "\n",
    "# Ensure the 'Average_Before' and 'Average_After' columns are numeric\n",
    "merged_df['Average_Before'] = pd.to_numeric(merged_df['Average_Before'], errors='coerce')\n",
    "merged_df['Average_After'] = pd.to_numeric(merged_df['Average_After'], errors='coerce')\n",
    "\n",
    "# Step 1: Sort the DataFrame by 'Average_Before' in ascending order\n",
    "merged_df = merged_df.sort_values(by='Average_Before').reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create a list of indices for companies to position them along the x-axis (sorted by 'before' rating)\n",
    "company_indices = range(len(merged_df))\n",
    "\n",
    "# Step 3: Plotting 'Before Greenwashing' points\n",
    "plt.scatter(company_indices, merged_df['Average_Before'], c='blue', label='Before Greenwashing', alpha=0.6)\n",
    "\n",
    "# Step 4: Plotting 'After Greenwashing' points with a different color\n",
    "plt.scatter(company_indices, merged_df['Average_After'], c='green', marker='x', label='After Greenwashing', alpha=0.6)\n",
    "\n",
    "# Step 5: Draw lines connecting the 'Before' and 'After' points for each company\n",
    "for i in company_indices:\n",
    "    plt.plot([i, i], [merged_df['Average_Before'][i], merged_df['Average_After'][i]], color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Step 6: Calculate the percentage of companies with a score increase of 0.5 or more\n",
    "merged_df['Rating_Increase'] = merged_df['Average_After'] - merged_df['Average_Before']\n",
    "companies_with_increase = merged_df[merged_df['Rating_Increase'] <= 0.2]\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage_increase = (len(companies_with_increase) / len(merged_df)) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Percentage of companies with a score decrease of 0.2 or less: {percentage_increase:.2f}%\")\n",
    "\n",
    "# Step 7: Calculate the rating increase for each company\n",
    "merged_df['Rating_Increase'] = merged_df['Average_After'] - merged_df['Average_Before']\n",
    "\n",
    "# Step 7: Create two subsets based on the 'Average_Before' range\n",
    "group_1_2_5 = merged_df[(merged_df['Average_Before'] >= 0) & (merged_df['Average_Before'] < 2.5)]\n",
    "group_2_5_5 = merged_df[(merged_df['Average_Before'] >= 2.5) & (merged_df['Average_Before'] <= 5)]\n",
    "\n",
    "# Step 8: Filter companies with a rating increase of 1 or more in each group\n",
    "group_1_2_5_increase = group_1_2_5[group_1_2_5['Rating_Increase'] >= 1]\n",
    "group_2_5_5_increase = group_2_5_5[group_2_5_5['Rating_Increase'] >= 1]\n",
    "\n",
    "# Step 9: Calculate the percentage of companies with a rating increase of 1 or more in each group\n",
    "percentage_1_2_5_increase = (len(group_1_2_5_increase) / len(group_1_2_5)) * 100 if len(group_1_2_5) > 0 else 0\n",
    "percentage_2_5_5_increase = (len(group_2_5_5_increase) / len(group_2_5_5)) * 100 if len(group_2_5_5) > 0 else 0\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"Percentage of companies with ratings between 0 and 2.5 that have a score increase of 1 or more: {percentage_1_2_5_increase:.2f}%\")\n",
    "print(f\"Percentage of companies with ratings between 2.5 and 5 that have a score increase of 1 or more: {percentage_2_5_5_increase:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Companies (Ordered by Before Greenwashing Rating)')\n",
    "plt.ylabel('Ratings')\n",
    "plt.title('Company Ratings Before and After Greenwashing (Stratified Set V1 NEW - Indicative)')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following plots 3 variations against the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# File paths for the different rating versions\n",
    "file_name_before_greenwashing = \"malicious_greenwashing_output/before_greenwashing_ratings_80.csv\"\n",
    "file_name_version_1 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v1_new/non_indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_2 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v2/non_indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_3 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v3/non_indicative/80_new_average_ratings.csv\"\n",
    "\n",
    "# Load the CSVs\n",
    "df_original = pd.read_csv(file_name_before_greenwashing)\n",
    "df_version_1 = pd.read_csv(file_name_version_1)\n",
    "df_version_2 = pd.read_csv(file_name_version_2)\n",
    "df_version_3 = pd.read_csv(file_name_version_3)\n",
    "\n",
    "# Merge the data on 'Company'\n",
    "merged_df = pd.merge(df_original[['Company', 'Average']], df_version_1[['Company', 'Average']], on='Company', suffixes=('_Original', '_V1'))\n",
    "merged_df = pd.merge(merged_df, df_version_2[['Company', 'Average']], on='Company')\n",
    "merged_df = pd.merge(merged_df, df_version_3[['Company', 'Average']], on='Company')\n",
    "\n",
    "# Rename columns\n",
    "merged_df.rename(columns={'Average': 'Average_V2', 'Average_x': 'Average_Original', 'Average_y': 'Average_V1', 'Average': 'Average_V3'}, inplace=True)\n",
    "\n",
    "# Merge datasets and check column names carefully after each merge\n",
    "merged_df = pd.merge(df_original[['Company', 'Average']], df_version_1[['Company', 'Average']], on='Company', suffixes=('_Original', '_V1'))\n",
    "\n",
    "# Merge the second version\n",
    "merged_df = pd.merge(merged_df, df_version_2[['Company', 'Average']], on='Company', how='left')\n",
    "merged_df.rename(columns={'Average': 'Average_V2'}, inplace=True)\n",
    "\n",
    "# Merge the third version\n",
    "merged_df = pd.merge(merged_df, df_version_3[['Company', 'Average']], on='Company', how='left')\n",
    "merged_df.rename(columns={'Average': 'Average_V3'}, inplace=True)\n",
    "\n",
    "# Check the column names\n",
    "print(merged_df.columns)\n",
    "\n",
    "# Ensure all necessary columns are numeric\n",
    "for col in ['Average_Original', 'Average_V1', 'Average_V2', 'Average_V3']:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "    else:\n",
    "        print(f\"Column {col} not found in DataFrame.\")\n",
    "\n",
    "\n",
    "# Check the structure of each column before attempting conversion to numeric\n",
    "print(merged_df['Average_Original'].head())\n",
    "print(merged_df['Average_V1'].head())\n",
    "print(merged_df['Average_V2'].head())\n",
    "print(merged_df['Average_V3'].head())\n",
    "\n",
    "# Ensure the columns are numeric\n",
    "for col in ['Average_Original', 'Average_V1', 'Average_V2', 'Average_V3']:\n",
    "    try:\n",
    "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "    except TypeError as e:\n",
    "        print(f\"Error converting column {col} to numeric: {e}\")\n",
    "\n",
    "# Ensure the columns are numeric\n",
    "for col in ['Average_Original', 'Average_V1', 'Average_V2', 'Average_V3']:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "\n",
    "# Sort the DataFrame by 'Average_Original'\n",
    "merged_df = merged_df.sort_values(by='Average_Original').reset_index(drop=True)\n",
    "\n",
    "# Create a list of indices for the x-axis (sorted by the original rating)\n",
    "company_indices = range(len(merged_df))\n",
    "\n",
    "# Plot each version against the original\n",
    "plt.scatter(company_indices, merged_df['Average_Original'], c='blue', label='Original', alpha=0.6)\n",
    "plt.scatter(company_indices, merged_df['Average_V1'], c='green', marker='x', label='Version 1', alpha=0.6)\n",
    "plt.scatter(company_indices, merged_df['Average_V2'], c='red', marker='o', label='Version 2', alpha=0.6)\n",
    "plt.scatter(company_indices, merged_df['Average_V3'], c='purple', marker='d', label='Version 3', alpha=0.6)\n",
    "\n",
    "# Draw lines connecting the original and each version's points for each company\n",
    "for i in company_indices:\n",
    "    plt.plot([i, i], [merged_df['Average_Original'][i], merged_df['Average_V1'][i]], color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.plot([i, i], [merged_df['Average_Original'][i], merged_df['Average_V2'][i]], color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.plot([i, i], [merged_df['Average_Original'][i], merged_df['Average_V3'][i]], color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Companies (Ordered by Original Rating)')\n",
    "plt.ylabel('Ratings')\n",
    "plt.title('Company Ratings After Greenwashing Without Indicative Scale')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heat graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for the different rating versions\n",
    "file_name_before_greenwashing = \"malicious_greenwashing_output/before_greenwashing_ratings_80.csv\"\n",
    "file_name_version_1 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v1_new/indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_2 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v2/indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_3 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v3/indicative/80_new_average_ratings.csv\"\n",
    "\n",
    "# Load the CSVs\n",
    "df_original = pd.read_csv(file_name_before_greenwashing)\n",
    "df_version_1 = pd.read_csv(file_name_version_1)\n",
    "df_version_2 = pd.read_csv(file_name_version_2)\n",
    "df_version_3 = pd.read_csv(file_name_version_3)\n",
    "\n",
    "# Check unique company names in each DataFrame\n",
    "print(\"Unique companies in original ratings:\", df_original['Company'].unique())\n",
    "print(\"Unique companies in version 1:\", df_version_1['Company'].unique())\n",
    "print(\"Unique companies in version 2:\", df_version_2['Company'].unique())\n",
    "print(\"Unique companies in version 3:\", df_version_3['Company'].unique())\n",
    "\n",
    "# Optionally, normalize company names to lowercase and strip spaces\n",
    "df_original['Company'] = df_original['Company'].str.lower().str.strip()\n",
    "df_version_1['Company'] = df_version_1['Company'].str.lower().str.strip()\n",
    "df_version_2['Company'] = df_version_2['Company'].str.lower().str.strip()\n",
    "df_version_3['Company'] = df_version_3['Company'].str.lower().str.strip()\n",
    "\n",
    "# Merge the data again\n",
    "merged_df = pd.merge(df_original[['Company', 'Average']], df_version_1[['Company', 'Average']], on='Company', suffixes=('_Original', '_V1'))\n",
    "merged_df = pd.merge(merged_df, df_version_2[['Company', 'Average']], on='Company', suffixes=('', '_V2'))\n",
    "merged_df = pd.merge(merged_df, df_version_3[['Company', 'Average']], on='Company', suffixes=('', '_V3'))\n",
    "\n",
    "# Print column names to check for any issues\n",
    "print(\"Columns after merge:\", merged_df.columns)\n",
    "\n",
    "# Rename columns correctly\n",
    "merged_df.rename(columns={'Average_Original': 'Average_Original', 'Average_V1': 'Average_V1', 'Average': 'Average_V2', 'Average_V3': 'Average_V3'}, inplace=True)\n",
    "\n",
    "# Print column names to check if renaming worked\n",
    "print(\"Columns after renaming:\", merged_df.columns)\n",
    "\n",
    "# Sort the DataFrame by 'Average_Original'\n",
    "merged_df = merged_df.sort_values(by='Average_Original').reset_index(drop=True)\n",
    "\n",
    "# Create a matrix for the heatmap\n",
    "heatmap_data = merged_df[['Average_Original', 'Average_V1', 'Average_V2', 'Average_V3']]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5, yticklabels=merged_df['Company'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Versions')\n",
    "plt.ylabel('Companies')\n",
    "plt.title('Heatmap of Company Ratings Across Different Versions (Indicative)')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "file_name_before_greenwashing = \"malicious_greenwashing_output/before_greenwashing_ratings_80.csv\"\n",
    "file_name_version_1 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v1_new/indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_2 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v2/indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_3 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v3/indicative/80_new_average_ratings.csv\"\n",
    "\n",
    "# Load the CSVs\n",
    "df_original = pd.read_csv(file_name_before_greenwashing)\n",
    "df_version_1 = pd.read_csv(file_name_version_1)\n",
    "df_version_2 = pd.read_csv(file_name_version_2)\n",
    "df_version_3 = pd.read_csv(file_name_version_3)\n",
    "\n",
    "\n",
    "# Normalize company names\n",
    "df_original['Company'] = df_original['Company'].str.lower().str.strip()\n",
    "df_version_1['Company'] = df_version_1['Company'].str.lower().str.strip()\n",
    "df_version_2['Company'] = df_version_2['Company'].str.lower().str.strip()\n",
    "df_version_3['Company'] = df_version_3['Company'].str.lower().str.strip()\n",
    "\n",
    "# Merge the data into a single DataFrame\n",
    "merged_df = pd.merge(df_original[['Company', 'Average']], df_version_1[['Company', 'Average']], on='Company', suffixes=('_Original', '_V1'))\n",
    "merged_df = pd.merge(merged_df, df_version_2[['Company', 'Average']], on='Company', suffixes=('', '_V2'))\n",
    "merged_df = pd.merge(merged_df, df_version_3[['Company', 'Average']], on='Company', suffixes=('', '_V3'))\n",
    "\n",
    "# Rename columns correctly\n",
    "merged_df.rename(columns={'Average_Original': 'Average_Original', 'Average_V1': 'Average_V1', 'Average': 'Average_V2', 'Average_V3': 'Average_V3'}, inplace=True)\n",
    "\n",
    "# Sort by original ratings\n",
    "merged_df = merged_df.sort_values(by='Average_Original').reset_index(drop=True)\n",
    "\n",
    "# Calculate the difference in ratings for each version\n",
    "merged_df['Diff_V1'] = merged_df['Average_V1'] - merged_df['Average_Original']\n",
    "merged_df['Diff_V2'] = merged_df['Average_V2'] - merged_df['Average_Original']\n",
    "merged_df['Diff_V3'] = merged_df['Average_V3'] - merged_df['Average_Original']\n",
    "\n",
    "# Bar Plot for Rating Differences\n",
    "plt.figure(figsize=(12, 8))\n",
    "merged_df[['Diff_V1', 'Diff_V2', 'Diff_V3']].plot(kind='bar', stacked=True)\n",
    "plt.title('Change in Ratings from Original to Each Greenwashing Version')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Rating Difference')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clustered Heatmap\n",
    "heatmap_data = merged_df[['Average_Original', 'Average_V1', 'Average_V2', 'Average_V3']]\n",
    "sns.clustermap(heatmap_data, cmap=\"coolwarm\", linewidths=0.5, annot=True)\n",
    "plt.title('Clustered Heatmap of Company Ratings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your CSV files\n",
    "file_name_before_greenwashing = \"malicious_greenwashing_output/before_greenwashing_ratings_80.csv\"\n",
    "file_name_version_1 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v1_new/non_indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_2 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v2/non_indicative/80_new_average_ratings.csv\"\n",
    "file_name_version_3 = \"malicious_greenwashing_output/testing_greenwashing_prompt_v3/non_indicative/80_new_average_ratings.csv\"\n",
    "\n",
    "# Load the CSVs\n",
    "df_original = pd.read_csv(file_name_before_greenwashing)\n",
    "df_version_1 = pd.read_csv(file_name_version_1)\n",
    "df_version_2 = pd.read_csv(file_name_version_2)\n",
    "df_version_3 = pd.read_csv(file_name_version_3)\n",
    "\n",
    "# Merge the data on 'Company'\n",
    "merged_df = pd.merge(df_original[['Company', 'Average']], df_version_1[['Company', 'Average']], on='Company', suffixes=('_Original', '_V1'))\n",
    "merged_df = pd.merge(merged_df, df_version_2[['Company', 'Average']], on='Company', suffixes=('', '_V2'))\n",
    "merged_df = pd.merge(merged_df, df_version_3[['Company', 'Average']], on='Company', suffixes=('', '_V3'))\n",
    "\n",
    "# Print column names to check for any issues\n",
    "print(\"Columns after merge:\", merged_df.columns)\n",
    "\n",
    "# Rename columns correctly\n",
    "merged_df.rename(columns={'Average_Original': 'Average_Original', 'Average_V1': 'Average_V1', 'Average_V2': 'Average_V2', 'Average': 'Average_V3'}, inplace=True)\n",
    "\n",
    "# Print column names to check if renaming worked\n",
    "print(\"Columns after renaming:\", merged_df.columns)\n",
    "\n",
    "# Sort the DataFrame by 'Average_Original'\n",
    "merged_df = merged_df.sort_values(by='Average_Original').reset_index(drop=True)\n",
    "\n",
    "# Check if 'Average_V2' exists in the DataFrame\n",
    "if 'Average_V2' not in merged_df.columns:\n",
    "    print(\"Error: 'Average_V2' column is missing.\")\n",
    "\n",
    "# Create a matrix for the heatmap\n",
    "heatmap_data = merged_df[['Average_Original', 'Average_V1', 'Average_V2', 'Average_V3']]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5, yticklabels=merged_df['Company'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Versions')\n",
    "plt.ylabel('Companies')\n",
    "plt.title('Heatmap of Company Ratings Across Different Versions')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to process the files and create the violin plot\n",
    "def create_violin_plot(file_indicative_before, file_indicative_after, \n",
    "                       file_non_indicative_before, file_non_indicative_after):\n",
    "    \n",
    "    # Load the CSV files into DataFrames\n",
    "    df_indicative_before = pd.read_csv(file_indicative_before)\n",
    "    df_indicative_after = pd.read_csv(file_indicative_after)\n",
    "    df_non_indicative_before = pd.read_csv(file_non_indicative_before)\n",
    "    df_non_indicative_after = pd.read_csv(file_non_indicative_after)\n",
    "    \n",
    "    # Merge the before and after data on 'Company' for both indicative and non-indicative\n",
    "    df_indicative = pd.merge(df_indicative_before, df_indicative_after, on='Company', suffixes=('_before', '_after'))\n",
    "    df_non_indicative = pd.merge(df_non_indicative_before, df_non_indicative_after, on='Company', suffixes=('_before', '_after'))\n",
    "\n",
    "    # Add a new column for the score increase (after greenwashing - before greenwashing)\n",
    "    df_indicative['Score_Increase'] = df_indicative['Average_after'] - df_indicative['Average_before']\n",
    "    df_non_indicative['Score_Increase'] = df_non_indicative['Average_after'] - df_non_indicative['Average_before']\n",
    "\n",
    "    # Define a function to categorize the companies by their original average score into custom bins\n",
    "    def categorize_score(score):\n",
    "        if 1 <= score < 1.5:\n",
    "            return '1-1.5'\n",
    "        elif 1.5 <= score < 2.5:\n",
    "            return '1.5-2.5'\n",
    "        elif 2.5 <= score < 3.5:\n",
    "            return '2.5-3.5'\n",
    "        elif 3.5 <= score < 4.5:\n",
    "            return '3.5-4.5'\n",
    "        elif 4.5 <= score <= 5:\n",
    "            return '4.5-5'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Apply the categorization to the 'Average_before' column\n",
    "    df_indicative['Score_Category'] = df_indicative['Average_before'].apply(categorize_score)\n",
    "    df_non_indicative['Score_Category'] = df_non_indicative['Average_before'].apply(categorize_score)\n",
    "\n",
    "    # Add a column to label the data as indicative or non-indicative\n",
    "    df_indicative['Type'] = 'Indicative'\n",
    "    df_non_indicative['Type'] = 'Non-Indicative'\n",
    "\n",
    "    # Combine the two dataframes into one for plotting\n",
    "    df_combined = pd.concat([df_indicative, df_non_indicative])\n",
    "\n",
    "    # Create an ordered list of categories for Score_Category\n",
    "    score_categories = ['1-1.5', '1.5-2.5', '2.5-3.5', '3.5-4.5', '4.5-5']\n",
    "\n",
    "    # Convert 'Score_Category' to an ordered categorical type\n",
    "    df_combined['Score_Category'] = pd.Categorical(df_combined['Score_Category'], categories=score_categories, ordered=True)\n",
    "\n",
    "    # Create the violin plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='Score_Category', y='Score_Increase', hue='Type', data=df_combined, split=True)\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title('Score Increase After Greenwashing Prompt V0: Indicative vs Non-Indicative')\n",
    "    plt.xlabel('Original Average Score')\n",
    "    plt.ylabel('Score Increase After Greenwashing')\n",
    "    plt.ylim(-1.5, 4)  # Set y-axis limits from -1 to 4\n",
    "    plt.legend(title='Type')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define file paths (these would be the paths to the actual CSV files)\n",
    "file_indicative_before = 'malicious_greenwashing_output/before_greenwashing_indicative_ratings_80.csv'\n",
    "file_indicative_after = 'malicious_greenwashing_output/testing_greenwashing_prompt_v0/indicative/indicative_80_new_average_ratings.csv'\n",
    "file_non_indicative_before = 'malicious_greenwashing_output/before_greenwashing_ratings_80.csv'\n",
    "file_non_indicative_after = 'malicious_greenwashing_output/testing_greenwashing_prompt_v0/non_indicative/non_indicative_80_new_average_ratings.csv'\n",
    "\n",
    "# Run the function (assuming the files are already available)\n",
    "create_violin_plot(file_indicative_before, file_indicative_after, file_non_indicative_before, file_non_indicative_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new violin plot where blue is v0, orange is v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to process the files and create the violin plot\n",
    "def create_violin_plot(file_non_indicative_before_v0, file_non_indicative_after_v0,\n",
    "                       file_non_indicative_before_v3, file_non_indicative_after_v3):\n",
    "    \n",
    "    # Load the CSV files into DataFrames\n",
    "    df_non_indicative_before_v0 = pd.read_csv(file_non_indicative_before_v0)\n",
    "    df_non_indicative_after_v0 = pd.read_csv(file_non_indicative_after_v0)\n",
    "    df_non_indicative_before_v3 = pd.read_csv(file_non_indicative_before_v3)\n",
    "    df_non_indicative_after_v3 = pd.read_csv(file_non_indicative_after_v3)\n",
    "    \n",
    "    # Merge the before and after data on 'Company' for both versions\n",
    "    df_non_indicative_v0 = pd.merge(df_non_indicative_before_v0, df_non_indicative_after_v0, on='Company', suffixes=('_before', '_after'))\n",
    "    df_non_indicative_v3 = pd.merge(df_non_indicative_before_v3, df_non_indicative_after_v3, on='Company', suffixes=('_before', '_after'))\n",
    "\n",
    "    # Add a new column for the score increase (after greenwashing - before greenwashing)\n",
    "    df_non_indicative_v0['Score_Increase'] = df_non_indicative_v0['Average_after'] - df_non_indicative_v0['Average_before']\n",
    "    df_non_indicative_v3['Score_Increase'] = df_non_indicative_v3['Average_after'] - df_non_indicative_v3['Average_before']\n",
    "\n",
    "    # Define a function to categorize the companies by their original average score into custom bins\n",
    "    def categorize_score(score):\n",
    "        if 1 <= score < 1.5:\n",
    "            return '1-1.5'\n",
    "        elif 1.5 <= score < 2.5:\n",
    "            return '1.5-2.5'\n",
    "        elif 2.5 <= score < 3.5:\n",
    "            return '2.5-3.5'\n",
    "        elif 3.5 <= score < 4.5:\n",
    "            return '3.5-4.5'\n",
    "        elif 4.5 <= score <= 5:\n",
    "            return '4.5-5'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Apply the categorization to the 'Average_before' column\n",
    "    df_non_indicative_v0['Score_Category'] = df_non_indicative_v0['Average_before'].apply(categorize_score)\n",
    "    df_non_indicative_v3['Score_Category'] = df_non_indicative_v3['Average_before'].apply(categorize_score)\n",
    "\n",
    "    # Add a column to label the data as version 0 or version 3\n",
    "    df_non_indicative_v0['Version'] = 'V0'\n",
    "    df_non_indicative_v3['Version'] = 'V3'\n",
    "\n",
    "    # Combine the two dataframes into one for plotting\n",
    "    df_combined = pd.concat([df_non_indicative_v0, df_non_indicative_v3])\n",
    "\n",
    "    # Create an ordered list of categories for Score_Category\n",
    "    score_categories = ['1-1.5', '1.5-2.5', '2.5-3.5', '3.5-4.5', '4.5-5']\n",
    "\n",
    "    # Convert 'Score_Category' to an ordered categorical type\n",
    "    df_combined['Score_Category'] = pd.Categorical(df_combined['Score_Category'], categories=score_categories, ordered=True)\n",
    "\n",
    "    # Create the violin plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(x='Score_Category', y='Score_Increase', hue='Version', data=df_combined, split=True)\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title('Score Increase After Greenwashing: Version 0 vs Version 3 (Non-Indicative)')\n",
    "    plt.xlabel('Original Average Score')\n",
    "    plt.ylabel('Score Increase After Greenwashing')\n",
    "    plt.ylim(-1.5, 4)  # Set y-axis limits from -1 to 4\n",
    "    plt.legend(title='Version')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define file paths (these would be the paths to the actual CSV files)\n",
    "file_non_indicative_before_v0 = 'malicious_greenwashing_output/before_greenwashing_ratings_80.csv'\n",
    "file_non_indicative_after_v0 = 'malicious_greenwashing_output/testing_greenwashing_prompt_v0/non_indicative/non_indicative_80_new_average_ratings.csv'\n",
    "file_non_indicative_before_v3 = 'malicious_greenwashing_output/before_greenwashing_ratings_80.csv'  # Assuming same before data\n",
    "file_non_indicative_after_v3 = 'malicious_greenwashing_output/testing_greenwashing_prompt_v3/non_indicative/80_new_average_ratings.csv'\n",
    "\n",
    "# Run the function (assuming the files are already available)\n",
    "create_violin_plot(file_non_indicative_before_v0, file_non_indicative_after_v0, \n",
    "                   file_non_indicative_before_v3, file_non_indicative_after_v3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "responses_file = \"malicious_greenwashing_output/testing_greenwashing_prompt_v0/80_new_responses.csv\"  # File 1: with responses\n",
    "new_scores_file = \"malicious_greenwashing_output/testing_greenwashing_prompt_v0/non_indicative/80_new_average_ratings.csv\"  # File 2: with new averages\n",
    "old_scores_file = \"malicious_greenwashing_output/before_greenwashing_non_indicative_ratings_80.csv\"  # File 3: with old averages\n",
    "output_file = \"malicious_greenwashing_output/word_count_data/v0_non_indicative.csv\"\n",
    "\n",
    "# Read the data\n",
    "responses_df = pd.read_csv(responses_file)\n",
    "new_scores_df = pd.read_csv(new_scores_file)\n",
    "old_scores_df = pd.read_csv(old_scores_file)\n",
    "\n",
    "# Replace NaN values with empty strings in response columns\n",
    "response_columns = [\"Old Response A\", \"Old Response B\", \"New Response A\", \"New Response B\"]\n",
    "responses_df[response_columns] = responses_df[response_columns].fillna(\"\")\n",
    "\n",
    "# Calculate word counts for old and new responses\n",
    "responses_df[\"Word Count Old Response\"] = (\n",
    "    responses_df[\"Old Response A\"].str.split().str.len() +\n",
    "    responses_df[\"Old Response B\"].str.split().str.len()\n",
    ")\n",
    "responses_df[\"Word Count New Response\"] = (\n",
    "    responses_df[\"New Response A\"].str.split().str.len() +\n",
    "    responses_df[\"New Response B\"].str.split().str.len()\n",
    ")\n",
    "\n",
    "# Create output DataFrame and merge with score data\n",
    "output_df = responses_df[[\"Company\", \"Word Count Old Response\", \"Word Count New Response\"]]\n",
    "output_df = output_df.merge(old_scores_df, on=\"Company\", how=\"left\").rename(columns={\"Average\": \"Average Old Response\"})\n",
    "output_df = output_df.merge(new_scores_df, on=\"Company\", how=\"left\").rename(columns={\"Average\": \"Average New Response\"})\n",
    "\n",
    "# Save to output file\n",
    "\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Output saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the output file\n",
    "output_file = \"malicious_greenwashing_output/word_count_data/v0_non_indicative.csv\"\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "# Scatter plot of word count vs. average score\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df, x=\"Word Count Old Response\", y=\"Average Old Response\", label=\"Old Response\", color=\"blue\")\n",
    "sns.scatterplot(data=df, x=\"Word Count New Response\", y=\"Average New Response\", label=\"New Response\", color=\"green\")\n",
    "plt.title(\"Word Count vs. Average Score V0 Non Indicative\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the output file\n",
    "output_file = \"malicious_greenwashing_output/word_count_data/v0_indicative.csv\"\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "output_plot_path = \"malicious_greenwashing_output/word_count_vs_score_plots/v0_indicative.png\"\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Draw lines connecting each company's Old and New points\n",
    "for i, row in df.iterrows():\n",
    "    plt.plot(\n",
    "        [row[\"Word Count Old Response\"], row[\"Word Count New Response\"]],\n",
    "        [row[\"Average Old Response\"], row[\"Average New Response\"]],\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=0.8,\n",
    "    )\n",
    "\n",
    "# Scatter plot for Old and New responses\n",
    "sns.scatterplot(data=df, x=\"Word Count Old Response\", y=\"Average Old Response\", label=\"Old Response\", color=\"blue\")\n",
    "sns.scatterplot(data=df, x=\"Word Count New Response\", y=\"Average New Response\", label=\"New Response\", color=\"green\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Word Count vs. Average Score V0 Indicative\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(output_plot_path, dpi=300)  # Save with high resolution (300 DPI)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the output file\n",
    "output_file = \"malicious_greenwashing_output/word_count_data/v3_indicative.csv\"\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "# Initialize a list to store slopes\n",
    "slopes = []\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Draw lines connecting each company's Old and New points\n",
    "for i, row in df.iterrows():\n",
    "    # Calculate the slope for the current line\n",
    "    delta_y = row[\"Average New Response\"] - row[\"Average Old Response\"]\n",
    "    delta_x = row[\"Word Count New Response\"] - row[\"Word Count Old Response\"]\n",
    "    slope = delta_y / delta_x if delta_x != 0 else 0  # Avoid division by zero\n",
    "    slopes.append(slope)\n",
    "    \n",
    "    # Plot the line\n",
    "    plt.plot(\n",
    "        [row[\"Word Count Old Response\"], row[\"Word Count New Response\"]],\n",
    "        [row[\"Average Old Response\"], row[\"Average New Response\"]],\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=0.8,\n",
    "    )\n",
    "\n",
    "# Scatter plot for Old and New responses\n",
    "sns.scatterplot(data=df, x=\"Word Count Old Response\", y=\"Average Old Response\", label=\"Old Response\", color=\"blue\")\n",
    "sns.scatterplot(data=df, x=\"Word Count New Response\", y=\"Average New Response\", label=\"New Response\", color=\"green\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Word Count vs. Average Score V0 Non Indicative\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# # Save the plot as a PNG file\n",
    "# output_plot_path = \"output_plots/word_count_vs_score_v0_non_indicative.png\"\n",
    "# plt.savefig(output_plot_path, dpi=300)  # Save with high resolution (300 DPI)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average slope\n",
    "average_slope = sum(slopes) / len(slopes)\n",
    "print(f\"Average slope of all lines: {average_slope:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# List of input files and corresponding response type labels\n",
    "file_paths = [\n",
    "    \"malicious_greenwashing_output/word_count_data/v0_non_indicative.csv\",\n",
    "    \"malicious_greenwashing_output/word_count_data/v1_non_indicative.csv\",\n",
    "    \"malicious_greenwashing_output/word_count_data/v2_non_indicative.csv\",\n",
    "    \"malicious_greenwashing_output/word_count_data/v3_non_indicative.csv\"\n",
    "]\n",
    "response_types = [\"Loose\", \"FixedLength\", \"FixedLength&Accuracy\", \"FixedAccuracy\"]\n",
    "\n",
    "# Initialize an empty DataFrame to combine all data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through the files, adding a 'ResponseType' column to differentiate them\n",
    "for file, response_type in zip(file_paths, response_types):\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"ResponseType\"] = response_type  # Add a column to label the response type\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# Preview combined data\n",
    "print(all_data.head())\n",
    "\n",
    "# Scatter plot of original word count vs. new ratings for all response types\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=all_data, \n",
    "    x=\"Word Count Old Response\", \n",
    "    y=\"Average Old Response\", \n",
    "    label=\"Original (All Types)\", \n",
    "    color=\"blue\", \n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Scatter plot of new word count vs. new ratings, differentiated by response type\n",
    "sns.scatterplot(\n",
    "    data=all_data, \n",
    "    x=\"Word Count New Response\", \n",
    "    y=\"Average New Response\", \n",
    "    hue=\"ResponseType\", \n",
    "    palette=\"tab10\", \n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "plt.title(\"Word Count vs. Average Score (Non Indicative, All Response Types)\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.legend(title=\"Response Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data for v2 and v3\n",
    "v2_file = \"malicious_greenwashing_output/word_count_data/v2_non_indicative.csv\"\n",
    "v3_file = \"malicious_greenwashing_output/word_count_data/v3_non_indicative.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "v2_df = pd.read_csv(v2_file)\n",
    "v3_df = pd.read_csv(v3_file)\n",
    "\n",
    "# Ensure the two dataframes have a common identifier for merging (e.g., CompanyID)\n",
    "if \"CompanyID\" not in v2_df.columns:\n",
    "    v2_df[\"CompanyID\"] = v2_df.index\n",
    "if \"CompanyID\" not in v3_df.columns:\n",
    "    v3_df[\"CompanyID\"] = v3_df.index\n",
    "\n",
    "# Merge the two datasets on CompanyID\n",
    "merged_df = pd.merge(v2_df, v3_df, on=\"CompanyID\", suffixes=(\"_V2\", \"_V3\"))\n",
    "\n",
    "# Initialize a list to store slopes\n",
    "slopes = []\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Draw lines connecting each company's V2 and V3 points\n",
    "for i, row in merged_df.iterrows():\n",
    "    # Calculate the slope for the current line\n",
    "    delta_y = row[\"Average New Response_V3\"] - row[\"Average New Response_V2\"]\n",
    "    delta_x = row[\"Word Count New Response_V3\"] - row[\"Word Count New Response_V2\"]\n",
    "    slope = delta_y / delta_x if delta_x != 0 else 0  # Avoid division by zero\n",
    "    slopes.append(slope)\n",
    "    \n",
    "    # Plot the line\n",
    "    plt.plot(\n",
    "        [row[\"Word Count New Response_V2\"], row[\"Word Count New Response_V3\"]],\n",
    "        [row[\"Average New Response_V2\"], row[\"Average New Response_V3\"]],\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=0.8,\n",
    "    )\n",
    "\n",
    "# Scatter plot for V2 and V3 responses\n",
    "sns.scatterplot(data=merged_df, x=\"Word Count New Response_V2\", y=\"Average New Response_V2\", label=\"V2\", color=\"blue\")\n",
    "sns.scatterplot(data=merged_df, x=\"Word Count New Response_V3\", y=\"Average New Response_V3\", label=\"V3\", color=\"green\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Comparison of Word Count and Average Score: V2 vs. V3\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "\n",
    "# plt.xlim(0, 400)  # Clip the x-axis range from 0 to 400\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file (optional)\n",
    "# output_plot_path = \"output_plots/word_count_vs_score_v2_v3.png\"\n",
    "# plt.savefig(output_plot_path, dpi=300)  # Save with high resolution (300 DPI)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average slope\n",
    "average_slope = sum(slopes) / len(slopes)\n",
    "print(f\"Average slope of all lines (V3 - V2): {average_slope:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Load the data for v2 and v3\n",
    "v2_file = \"malicious_greenwashing_output/word_count_data/v2_non_indicative.csv\"\n",
    "v3_file = \"malicious_greenwashing_output/word_count_data/v3_non_indicative.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "v2_df = pd.read_csv(v2_file)\n",
    "v3_df = pd.read_csv(v3_file)\n",
    "\n",
    "# Ensure the two dataframes have a common identifier for merging (e.g., CompanyID)\n",
    "if \"CompanyID\" not in v2_df.columns:\n",
    "    v2_df[\"CompanyID\"] = v2_df.index\n",
    "if \"CompanyID\" not in v3_df.columns:\n",
    "    v3_df[\"CompanyID\"] = v3_df.index\n",
    "\n",
    "# Merge the two datasets on CompanyID\n",
    "merged_df = pd.merge(v2_df, v3_df, on=\"CompanyID\", suffixes=(\"_V2\", \"_V3\"))\n",
    "\n",
    "# Calculate the change in word count and the change in rating\n",
    "merged_df[\"Change in Word Count\"] = merged_df[\"Word Count New Response_V3\"] - merged_df[\"Word Count New Response_V2\"]\n",
    "merged_df[\"Change in Rating\"] = merged_df[\"Average New Response_V3\"] - merged_df[\"Average New Response_V2\"]\n",
    "\n",
    "# Perform linear regression to get the line of best fit\n",
    "x = merged_df[\"Change in Word Count\"]\n",
    "y = merged_df[\"Change in Rating\"]\n",
    "\n",
    "# Perform the regression using linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "r_squared = r_value ** 2\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=merged_df, x=\"Change in Word Count\", y=\"Change in Rating\", color=\"purple\", alpha=0.7)\n",
    "\n",
    "# # Add a vertical and horizontal line at 0 for reference\n",
    "plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.axvline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x, slope * x + intercept, color=\"red\", label=f\"Line of Best Fit: R²={r_squared:.4f}\")\n",
    "\n",
    "# # Crop the x-axis from -200 to 200\n",
    "# plt.xlim(-200, 200)\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Change in Word Count vs. Change in Rating (V2 to V3)\")\n",
    "plt.xlabel(\"Change in Word Count\")\n",
    "plt.ylabel(\"Change in Rating\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file (optional)\n",
    "# output_plot_path = \"output_plots/change_word_count_vs_rating_v2_v3.png\"\n",
    "# plt.savefig(output_plot_path, dpi=300)  # Save with high resolution (300 DPI)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display summary statistics\n",
    "average_change_word_count = merged_df[\"Change in Word Count\"].mean()\n",
    "average_change_rating = merged_df[\"Change in Rating\"].mean()\n",
    "\n",
    "print(f\"Average change in word count: {average_change_word_count:.2f}\")\n",
    "print(f\"Average change in rating: {average_change_rating:.2f}\")\n",
    "print(f\"R-squared value: {r_squared:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
